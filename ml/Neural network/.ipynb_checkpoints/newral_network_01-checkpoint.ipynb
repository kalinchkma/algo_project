{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115730ef",
   "metadata": {},
   "source": [
    "# Neural Network from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "898828bf-c849-4c5f-8461-70d7a8b31f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d0be8a",
   "metadata": {},
   "source": [
    "## Single neuron\n",
    "\n",
    "- Each Neuron has a input, weight and biases\n",
    "- Weight and bias changes during training\n",
    "- The value of weight and biases are what get trained, and they are what make a model work or not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16fa1c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.499999999999999\n"
     ]
    }
   ],
   "source": [
    "# Example of neuron that has a weights and bias\n",
    "'''\n",
    "This single neuron has a three inputs, \n",
    "- One neuron has only one bias\n",
    "'''\n",
    "inputs = [5, 7, 9]\n",
    "weights = [0.4, 0.7, -0.3]\n",
    "bias = 2.3\n",
    "\n",
    "# Output of this neuron\n",
    "'''\n",
    "Neuron calculation\n",
    "-> output = input*weights + bias\n",
    "'''\n",
    "output = (inputs[0]*weights[0] +\n",
    "          inputs[1]*weights[1] +\n",
    "          inputs[2]*weights[2] + bias)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "348f5344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8\n"
     ]
    }
   ],
   "source": [
    "# Ex: Neuron with four inputs\n",
    "# ---\n",
    "# Neuron inputs\n",
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [0.2, 0.8, -0.5, 1.0]\n",
    "bias = 2.0\n",
    "# Neuron outputs\n",
    "output = inputs[0]*weights[0] + inputs[1]*weights[1] + inputs[2]*weights[2] + inputs[3]*weights[3] + bias\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cdf5ab",
   "metadata": {},
   "source": [
    "## A Layer of Neurons\n",
    "\n",
    "- In NN typically have layers that consist of more than one neuron. Layers are nothing more than groups of neurons\n",
    "- Neuron input can be trained data or output from previous neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b000977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "# Eg: layes that has 3 neuron and 4 inputs\n",
    "#---\n",
    "# inputs\n",
    "inputs = [1, 2, 3, 2.5]\n",
    "\n",
    "# weigths\n",
    "weights1 = [0.2, 0.8, -0.5, 1.0]\n",
    "weights2 = [0.5, -0.91, 0.26, -0.5]\n",
    "weights3 = [-0.26, -0.27, 0.17, 0.87]\n",
    "\n",
    "# bias\n",
    "bias1 = 2\n",
    "bias2 = 3\n",
    "bias3 = 0.5\n",
    "\n",
    "# layers of neurons\n",
    "layer = [\n",
    "    # Neuron 1:\n",
    "    inputs[0]*weights1[0] +\n",
    "    inputs[1]*weights1[1] +\n",
    "    inputs[2]*weights1[2] +\n",
    "    inputs[3]*weights1[3] + bias1,\n",
    "    \n",
    "    # Neuron 2:\n",
    "    inputs[0]*weights2[0] +\n",
    "    inputs[1]*weights2[1] +\n",
    "    inputs[2]*weights2[2] +\n",
    "    inputs[3]*weights2[3] + bias2,\n",
    "    \n",
    "    # Neuron 3:\n",
    "    inputs[0]*weights3[0] +\n",
    "    inputs[1]*weights3[1] +\n",
    "    inputs[2]*weights3[2] +\n",
    "    inputs[3]*weights3[3] + bias3\n",
    "]\n",
    "\n",
    "print(layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169e848f",
   "metadata": {},
   "source": [
    "## Upgrading current method of calculating nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceb03a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "# Previous exemple with upgraded method\n",
    "# initial inputs, weight and biases\n",
    "inputs = [1, 2, 3, 2.5]\n",
    "weights = [[0.2, 0.8, -0.5, 1],\n",
    "           [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "# Output layers\n",
    "layer = []\n",
    "\n",
    "# Iterare for each neuron\n",
    "for neuron_weights, neuron_bias in zip(weights, biases):\n",
    "    # Output of given neuron\n",
    "    neuron_output = 0\n",
    "    # calulating for each input and weight\n",
    "    for n_input, weight in zip(inputs, neuron_weights):\n",
    "        # Multiply this input by associated weight\n",
    "        # and add to the neuron output variable\n",
    "        neuron_output += n_input*weight\n",
    "    # Add bias to neuron\n",
    "    neuron_output += neuron_bias\n",
    "    # Put neuron output to layer\n",
    "    layer.append(neuron_output)\n",
    "\n",
    "print(layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5706d5ad",
   "metadata": {},
   "source": [
    "## Tensor, Arrays and Vectors\n",
    "\n",
    "- A Tensor object is an object that can be represented as an array\n",
    "- Vector can be call a list in Python and Array others\n",
    "- Matrics can be call list of list on Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ae91150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2, 4, 9], [5, 3, 5]], [[5, 8, 1], [4, 7, 9.2]]] \n",
      " [2, 4, 1, 4] \n",
      " [[3, 2], [4, 1], [2, 1]]\n"
     ]
    }
   ],
   "source": [
    "tensor = [[[2, 4, 9],\n",
    "          [5, 3, 5]],\n",
    "         [[5, 8, 1],\n",
    "          [4, 7,9.2]]]\n",
    "\n",
    "vector = [2, 4, 1, 4] # array\n",
    "\n",
    "matrics = [[3, 2],\n",
    "          [4, 1],\n",
    "          [2, 1]]\n",
    "\n",
    "print(tensor,\"\\n\",vector,\"\\n\", matrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a29654d",
   "metadata": {},
   "source": [
    "## Dot Product and Vector Addition\n",
    "- A dot product of two vectors is a sum of product of consecutive vector elements\n",
    "- Both vectors must be of the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4acd782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "b = [2, 3, 4]\n",
    "dot_product = a[0]*b[0] + a[1]*b[1] + a[2]*b[2]\n",
    "dot_product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a257706",
   "metadata": {},
   "source": [
    "## Single Neuron with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17bce684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [0.2, 0.8, -0.5, 1.0]\n",
    "bias = 2.0\n",
    "\n",
    "output = np.dot(weights, inputs) + bias\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d245c58",
   "metadata": {},
   "source": [
    "## A Layer of Neurons with NumPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "629bcc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.8  , 1.21 , 2.385])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [[0.2, 0.8, -0.5, 1],\n",
    "          [0.5, -0.91, 0.26, -0.5],\n",
    "          [-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2.0, 3.0, 0.5]\n",
    "\n",
    "layer_outputs = np.dot(weights, inputs) + biases\n",
    "\n",
    "layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8b8e65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1. , 2. , 3. , 2.5]),\n",
       " array([[ 0.2 ,  0.8 , -0.5 ,  1.  ],\n",
       "        [ 0.5 , -0.91,  0.26, -0.5 ],\n",
       "        [-0.26, -0.27,  0.17,  0.87]]),\n",
       " array([2. , 3. , 0.5]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = np.array([1.0, 2.0, 3.0, 2.5])\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1],\n",
    "          [0.5, -0.91, 0.26, -0.5],\n",
    "          [-0.26, -0.27, 0.17, 0.87]])\n",
    "biases = np.array([2.0, 3.0, 0.5])\n",
    "inputs, weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75fd0d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34, 50])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1 = [[1, 2, 4],\n",
    "       [2, 4, 5]]\n",
    "mat2 = [2, 4, 6]\n",
    "np.dot(mat1, mat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219cc0fc",
   "metadata": {},
   "source": [
    "**NOTE**: When it comes to dot product \n",
    "```\n",
    "    array[2, 4, 7] \n",
    "    \n",
    "    array[[2],                                                    \n",
    "          [4], \n",
    "          [7]] \n",
    " ```\n",
    " Are same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a385fd4",
   "metadata": {},
   "source": [
    "## A Batch of Data \n",
    "\n",
    "- A Batch is a sample of data that given as a inputs at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a30f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [[2, 4, 2],\n",
    "        [3, 5, 1],\n",
    "        [5, 8, 9],\n",
    "        [1, 2, 4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea0e506",
   "metadata": {},
   "source": [
    "## Matrix Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e1e082d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 30,  63,  17],\n",
       "       [ 21,  66,  25],\n",
       "       [ 37, 104,  39]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1 = [[2, 4, 5],\n",
    "       [4, 5, 1],\n",
    "       [6, 7, 3]]\n",
    "mat2 = [[3, 9, 6],\n",
    "       [1, 5, 0],\n",
    "       [4, 5, 1]]\n",
    "np.dot(mat1, mat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec948ee",
   "metadata": {},
   "source": [
    "## Transposition of the matrix product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6f044e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 2]\n",
      " [3 1 5]\n",
      " [5 8 1]] \n",
      "\n",
      "[[1 3 5]\n",
      " [3 1 8]\n",
      " [2 5 1]]\n"
     ]
    }
   ],
   "source": [
    "mat = np.array([\n",
    "       [1, 3, 2],\n",
    "       [3, 1, 5],\n",
    "       [5, 8, 1]\n",
    "      ])\n",
    "print(mat, \"\\n\")\n",
    "print(np.transpose(mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c8a122b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 2 9]]\n",
      "------------------\n",
      "[[[1 2 3]\n",
      "  [4 2 9]]] 3 2\n",
      "------------------\n",
      "[[[1 2 3]]\n",
      "\n",
      " [[4 2 9]]] 3 2\n"
     ]
    }
   ],
   "source": [
    "# array expense\n",
    "a = np.array([[1, 2, 3], [4, 2, 9]])\n",
    "a2 = np.array([a])\n",
    "a3 = np.expand_dims(np.array(a), axis=1)\n",
    "print(a)\n",
    "print(\"------------------\")\n",
    "print(a2, a2.ndim, a.ndim)\n",
    "print(\"------------------\")\n",
    "print(a3, a3.ndim, a.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98c91ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1 4]\n",
      " [5 1 7]\n",
      " [6 2 3]] 2\n",
      "------------\n",
      "[[[2 1 4]]\n",
      "\n",
      " [[5 1 7]]\n",
      "\n",
      " [[6 2 3]]] 3\n"
     ]
    }
   ],
   "source": [
    "mat = np.array([[2, 1, 4], [5, 1, 7], [6, 2, 3]])\n",
    "print(mat, mat.ndim)\n",
    "print(\"------------\")\n",
    "print(np.expand_dims(mat, axis=1), np.expand_dims(mat, axis=1).ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e43d7fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]]\n",
      "[[2]\n",
      " [3]\n",
      " [4]]\n",
      "[[ 2  4  6]\n",
      " [ 3  6  9]\n",
      " [ 4  8 12]] 2 2\n"
     ]
    }
   ],
   "source": [
    "# transpose\n",
    "a = [1, 2, 3]\n",
    "b = [2, 3, 4]\n",
    "\n",
    "a = np.array([a])\n",
    "b = np.array([b]).T\n",
    "print(a)\n",
    "print(b)\n",
    "print(np.dot(b, a), a.ndim, b.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec3fc3",
   "metadata": {},
   "source": [
    "## A Layer of Neurons & Batch of Data with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6f1f238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "inputs = [[1.0, 2.0, 3.0, 2.5],\n",
    "         [2.0, 5.0, -1.0, 2.0],\n",
    "         [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "          [0.5, -0.91, 0.26, -0.5],\n",
    "          [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "biases = [2.0, 3.0, 0.5]\n",
    "\n",
    "outputs = np.dot(inputs, np.array(weights).T) + biases\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd75e02",
   "metadata": {},
   "source": [
    "## Adding Layers\n",
    "\n",
    "- Neural network with two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db15950f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: output\n",
      " [[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n",
      "Layer 2: output\n",
      " [[ 0.5031  -1.04185 -2.03875]\n",
      " [ 0.2434  -2.7332  -5.7633 ]\n",
      " [-0.99314  1.41254 -0.35655]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [[1, 2, 3, 2.5],\n",
    "         [2., 5., -1., 2.],\n",
    "         [-1.5, 2.7, 3.3, -0.8]]\n",
    "# Layer 1: weights & biases\n",
    "weights = [[0.2, 0.8, -0.5, 1],\n",
    "          [0.5, -0.91, 0.26, -0.5],\n",
    "          [-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "# Layer 2: weights & biases\n",
    "weights2 = [[0.1, -0.14, 0.5],\n",
    "          [-0.5, 0.12, -0.33],\n",
    "          [-0.44, 0.73, -0.13]]\n",
    "\n",
    "biases2 = [-1, 2, -0.5]\n",
    "\n",
    "# Layer 1: Calculation\n",
    "layer1 = np.dot(inputs, np.array(weights).T) + biases\n",
    "\n",
    "# Layer 2: Calculation\n",
    "layer2 = np.dot(layer1, np.array(weights2).T) + biases2\n",
    "\n",
    "print(\"Layer 1: output\\n\",layer1)\n",
    "print(\"Layer 2: output\\n\",layer2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cab00fa-fc33-4ab2-8e53-68b3053c977b",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "017110fe-3162-402c-a7bb-3be31fb90c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../data/heart-disease.csv\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bf0968f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4242"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cd052617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[63.,  1.,  3., ...,  0.,  0.,  1.],\n",
       "        [37.,  1.,  2., ...,  0.,  0.,  2.],\n",
       "        [41.,  0.,  1., ...,  2.,  0.,  2.],\n",
       "        ...,\n",
       "        [68.,  1.,  0., ...,  1.,  2.,  3.],\n",
       "        [57.,  1.,  0., ...,  1.,  1.,  3.],\n",
       "        [57.,  0.,  1., ...,  1.,  1.,  2.]]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.drop(\"target\", axis=1).to_numpy()\n",
    "\n",
    "target = df[\"target\"].to_numpy()\n",
    "features, target, features.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2f6a6997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6.30e+01, 1.00e+00, 3.00e+00, 1.45e+02, 2.33e+02, 1.00e+00,\n",
       "         0.00e+00, 1.50e+02, 0.00e+00, 2.30e+00, 0.00e+00, 0.00e+00,\n",
       "         1.00e+00],\n",
       "        [3.70e+01, 1.00e+00, 2.00e+00, 1.30e+02, 2.50e+02, 0.00e+00,\n",
       "         1.00e+00, 1.87e+02, 0.00e+00, 3.50e+00, 0.00e+00, 0.00e+00,\n",
       "         2.00e+00],\n",
       "        [4.10e+01, 0.00e+00, 1.00e+00, 1.30e+02, 2.04e+02, 0.00e+00,\n",
       "         0.00e+00, 1.72e+02, 0.00e+00, 1.40e+00, 2.00e+00, 0.00e+00,\n",
       "         2.00e+00],\n",
       "        [5.60e+01, 1.00e+00, 1.00e+00, 1.20e+02, 2.36e+02, 0.00e+00,\n",
       "         1.00e+00, 1.78e+02, 0.00e+00, 8.00e-01, 2.00e+00, 0.00e+00,\n",
       "         2.00e+00],\n",
       "        [5.70e+01, 0.00e+00, 0.00e+00, 1.20e+02, 3.54e+02, 0.00e+00,\n",
       "         1.00e+00, 1.63e+02, 1.00e+00, 6.00e-01, 2.00e+00, 0.00e+00,\n",
       "         2.00e+00],\n",
       "        [5.70e+01, 1.00e+00, 0.00e+00, 1.40e+02, 1.92e+02, 0.00e+00,\n",
       "         1.00e+00, 1.48e+02, 0.00e+00, 4.00e-01, 1.00e+00, 0.00e+00,\n",
       "         1.00e+00],\n",
       "        [5.60e+01, 0.00e+00, 1.00e+00, 1.40e+02, 2.94e+02, 0.00e+00,\n",
       "         0.00e+00, 1.53e+02, 0.00e+00, 1.30e+00, 1.00e+00, 0.00e+00,\n",
       "         2.00e+00],\n",
       "        [4.40e+01, 1.00e+00, 1.00e+00, 1.20e+02, 2.63e+02, 0.00e+00,\n",
       "         1.00e+00, 1.73e+02, 0.00e+00, 0.00e+00, 2.00e+00, 0.00e+00,\n",
       "         3.00e+00],\n",
       "        [5.20e+01, 1.00e+00, 2.00e+00, 1.72e+02, 1.99e+02, 1.00e+00,\n",
       "         1.00e+00, 1.62e+02, 0.00e+00, 5.00e-01, 2.00e+00, 0.00e+00,\n",
       "         3.00e+00],\n",
       "        [5.70e+01, 1.00e+00, 2.00e+00, 1.50e+02, 1.68e+02, 0.00e+00,\n",
       "         1.00e+00, 1.74e+02, 0.00e+00, 1.60e+00, 2.00e+00, 0.00e+00,\n",
       "         2.00e+00],\n",
       "        [5.40e+01, 1.00e+00, 0.00e+00, 1.40e+02, 2.39e+02, 0.00e+00,\n",
       "         1.00e+00, 1.60e+02, 0.00e+00, 1.20e+00, 2.00e+00, 0.00e+00,\n",
       "         2.00e+00],\n",
       "        [4.80e+01, 0.00e+00, 2.00e+00, 1.30e+02, 2.75e+02, 0.00e+00,\n",
       "         1.00e+00, 1.39e+02, 0.00e+00, 2.00e-01, 2.00e+00, 0.00e+00,\n",
       "         2.00e+00],\n",
       "        [4.90e+01, 1.00e+00, 1.00e+00, 1.30e+02, 2.66e+02, 0.00e+00,\n",
       "         1.00e+00, 1.71e+02, 0.00e+00, 6.00e-01, 2.00e+00, 0.00e+00,\n",
       "         2.00e+00],\n",
       "        [6.40e+01, 1.00e+00, 3.00e+00, 1.10e+02, 2.11e+02, 0.00e+00,\n",
       "         0.00e+00, 1.44e+02, 1.00e+00, 1.80e+00, 1.00e+00, 0.00e+00,\n",
       "         2.00e+00],\n",
       "        [5.80e+01, 0.00e+00, 3.00e+00, 1.50e+02, 2.83e+02, 1.00e+00,\n",
       "         0.00e+00, 1.62e+02, 0.00e+00, 1.00e+00, 2.00e+00, 0.00e+00,\n",
       "         2.00e+00]]),\n",
       " 15,\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 15)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = features[:15]\n",
    "target = target[:15]\n",
    "features, len(features), target, target.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcebb747",
   "metadata": {},
   "source": [
    "## Dense Layer Class\n",
    "\n",
    "- reuseable dense layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9ae53097",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_Layer:\n",
    "    \n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        # initialize weights and biases\n",
    "        # random weights and biases initialization (Note: we can some use rules to initialize)  \n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "        \n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Calculate output values from inputs, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da273cf",
   "metadata": {},
   "source": [
    "## Creating Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "85006662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.7324994  -1.19714928  4.84659565 -1.62733325 -1.71916107]\n",
      " [-1.03074887 -1.41346654  4.67012527 -1.29478684 -2.30465717]\n",
      " [-0.69102979 -1.2300923   4.17319853 -1.24792792 -2.02964   ]\n",
      " [-1.43135324 -1.30680445  4.56936351 -1.1356696  -1.74354371]\n",
      " [-3.3861265  -1.45038866  5.88727312 -1.47795393 -1.95449583]\n",
      " [-1.12995789 -1.12003054  4.22416125 -1.42460242 -1.64712902]\n",
      " [-2.51156072 -1.30623402  5.40504391 -1.6577584  -1.98061307]\n",
      " [-1.67156293 -1.33330639  4.76746793 -1.22788533 -2.02163409]\n",
      " [-0.74018664 -1.2218841   4.63230659 -1.84428056 -2.18247194]\n",
      " [-0.33255104 -1.21033183  4.10710184 -1.43154857 -1.8495672 ]\n",
      " [-1.57602444 -1.25734169  4.74714878 -1.493292   -1.890035  ]\n",
      " [-2.35925007 -1.2157865   5.01623727 -1.60908115 -1.92606821]\n",
      " [-1.79067311 -1.34428052  4.93926593 -1.38505135 -2.02673552]\n",
      " [-1.68819838 -1.10725264  4.24206892 -1.16777661 -1.25866664]\n",
      " [-2.21081083 -1.32919387  5.44731664 -1.76770561 -2.07939268]]\n"
     ]
    }
   ],
   "source": [
    "# Create First desne layer: \n",
    "dense1 = Dense_Layer(13, 5)\n",
    "\n",
    "# Forward pass\n",
    "dense1.forward(features)\n",
    "\n",
    "print(dense1.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65ea71f",
   "metadata": {},
   "source": [
    "## Activation Function\n",
    "\n",
    "### The Step Activation Function\n",
    "\n",
    "The purpose of this function serves is to mimic a neuron \"firing\" or \"not firing\" based on input information.\n",
    "\n",
    "In a single neuron, if the weight.inputs + bias results in a value greater than 0, the neuron will fire and output a 0; otherwise, it will output a 0.\n",
    "\n",
    "This activation function has been used historically in hidden layers, but nowadays, it is rarely a choice.\n",
    "\n",
    "```\n",
    "y = {\n",
    "      0 if x <= 0\n",
    "      1 if x >  0\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809ce857",
   "metadata": {},
   "source": [
    "### The Linear Activation Function\n",
    "\n",
    "A Linear function is simply the equation of a line. it will appear as a straight line when graphed, where `y=x` and the output value equals the input.<br />\n",
    "\n",
    "This activation  function is usually applied to the last layer's output in the case of a regression modal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20704c4",
   "metadata": {},
   "source": [
    "### The Sigmoid Activation Function\n",
    "\n",
    "```\n",
    "y = 1/(1+e^-x)\n",
    "```\n",
    "This activation function is more granular for neural network. <br />\n",
    "\n",
    "This function returns a value in the range of 0 for negative infinity, through 0.5 for the input of 0, and to 1 for positive infinity.<br />\n",
    "\n",
    "The **Sigmoid** function is replaced by **ReLU** function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e717f4",
   "metadata": {},
   "source": [
    "### The Rectified Linear Activation Function\n",
    "\n",
    "```\n",
    "y = {\n",
    "    x x >  0\n",
    "    0 x <= 0\n",
    "}\n",
    "```\n",
    "The **ReLU** finction is simpler than the sigmoid. It's quite literally `y=x`.<br />\n",
    "\n",
    "If `x` is less than or equal to 0, then `y` is 0 otherwise, `y` is equal to `x`. <br />\n",
    "\n",
    "This function simple but most widely used activation function. <br />\n",
    "\n",
    "The ReLU Activation function is extremely close to being a linear activation function while remaining nonlinear, due to that bend after 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a0bedb",
   "metadata": {},
   "source": [
    "### Linear Activation in the Hidden Layers\n",
    "\n",
    "If we use linear function in a neural network, No matter what we do, with the neuron's weights and biases, the output of this neuron will be perfectly linear to `y=x` of the activation function. This linear nature will continue throughout the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70344e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer with linear activation function\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
